{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM,Dense,Activation,Dropout,RepeatVector,Embedding,TimeDistributed, Add, Input\n",
    "from tensorflow.keras.applications import ResNet50 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25493, 40)\n",
      "(25493, 8254)\n",
      "(25493, 2048)\n",
      "(25493,)\n",
      "8254\n"
     ]
    }
   ],
   "source": [
    "captions = np.load(\"./captions.npy\")\n",
    "next_words = np.load(\"./next_words.npy\")\n",
    "images = np.load(\"./images.npy\")\n",
    "image_names = np.load('./image_names.npy')\n",
    "\n",
    "print(captions.shape)\n",
    "print(next_words.shape)\n",
    "print(images.shape)\n",
    "print(image_names.shape)\n",
    "\n",
    "with open('./word_2_indices.p','rb') as fi:\n",
    "    word_2_indices = pickle.load(fi)\n",
    "vocab_size = len(word_2_indices)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 128\n",
    "max_len = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 2048)]            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 40, 128)           0         \n",
      "=================================================================\n",
      "Total params: 262,272\n",
      "Trainable params: 262,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_model_inp = Input(shape=(2048,))\n",
    "image_model_ly1 = Dense(embedding_size, activation='relu')(image_model_inp)\n",
    "image_model_ly2 = RepeatVector(max_len)(image_model_ly1)\n",
    "\n",
    "image_model = Model(inputs =image_model_inp,outputs = image_model_ly2)\n",
    "image_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 40)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 40, 128)           1056512   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 40, 256)           394240    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 40, 128)           32896     \n",
      "=================================================================\n",
      "Total params: 1,483,648\n",
      "Trainable params: 1,483,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "language_model_inp = Input(shape=(max_len,))\n",
    "language_model_ly1 = Embedding(input_dim=vocab_size, output_dim=embedding_size)(language_model_inp)\n",
    "language_model_ly2 = LSTM(256, return_sequences=True)(language_model_ly1)\n",
    "language_model_ly3 = TimeDistributed(Dense(embedding_size))(language_model_ly2)\n",
    "\n",
    "language_model = Model(inputs=language_model_inp,outputs=language_model_ly3)\n",
    "language_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ly1 = Add()([image_model_ly2, language_model_ly3])\n",
    "model_ly2 = LSTM(128, return_sequences=True)(model_ly1)\n",
    "model_ly3 = LSTM(512, return_sequences=False)(model_ly2)\n",
    "model_ly4 = Dense(vocab_size,activation = 'softmax')(model_ly3)\n",
    "\n",
    "\n",
    "model = Model(inputs = [image_model_inp,language_model_inp],outputs = model_ly4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25493 samples\n",
      "Epoch 1/10\n",
      "25493/25493 [==============================] - 173s 7ms/sample - loss: 6.5166 - accuracy: 0.0915\n",
      "Epoch 2/10\n",
      "25493/25493 [==============================] - 205s 8ms/sample - loss: 4.9479 - accuracy: 0.1505\n",
      "Epoch 3/10\n",
      "25493/25493 [==============================] - 213s 8ms/sample - loss: 4.6287 - accuracy: 0.1784\n",
      "Epoch 4/10\n",
      "25493/25493 [==============================] - 211s 8ms/sample - loss: 4.2910 - accuracy: 0.2287\n",
      "Epoch 5/10\n",
      "25493/25493 [==============================] - 215s 8ms/sample - loss: 4.0243 - accuracy: 0.2594\n",
      "Epoch 6/10\n",
      "25493/25493 [==============================] - 219s 9ms/sample - loss: 3.8360 - accuracy: 0.2734\n",
      "Epoch 7/10\n",
      "25493/25493 [==============================] - 198s 8ms/sample - loss: 3.6605 - accuracy: 0.2857\n",
      "Epoch 8/10\n",
      "25493/25493 [==============================] - 199s 8ms/sample - loss: 3.5151 - accuracy: 0.2944\n",
      "Epoch 9/10\n",
      "25493/25493 [==============================] - 201s 8ms/sample - loss: 3.3504 - accuracy: 0.3122\n",
      "Epoch 10/10\n",
      "25493/25493 [==============================] - 199s 8ms/sample - loss: 3.2087 - accuracy: 0.3254\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"./model_weights.h5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "hist = model.fit([images, captions], next_words, batch_size=512, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
